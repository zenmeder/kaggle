{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('./digitRecognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\n   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n1     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n2     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n3     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n4     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n\n   pixel779  pixel780  pixel781  pixel782  pixel783  \n0       0.0       0.0       0.0       0.0       0.0  \n1       0.0       0.0       0.0       0.0       0.0  \n2       0.0       0.0       0.0       0.0       0.0  \n3       0.0       0.0       0.0       0.0       0.0  \n4       0.0       0.0       0.0       0.0       0.0  \n\n[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X, y = data.iloc[:,1:].astype('float')/255,data.iloc[:,:1]\n",
    "print(X.head())\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y)\n",
    "y = enc.transform(y).toarray()\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y1, y2 = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29400, 784) (12600, 784) (29400, 10) (12600, 10)\n[<class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>]\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape, x2.shape, y1.shape, y2.shape)\n",
    "print([_ for _ in map(type, [x1,x2,y1,y2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1],padding='SAME')\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='input')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10], name='output')\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
    "h_pool1 = max_pool(h_conv1)\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2)\n",
    "h_pool2 = max_pool(h_conv2)\n",
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2)\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_random_cached(x1, y1, size):\n",
    "    a, b = [],[]\n",
    "    n = len(x1)\n",
    "    for i in range(size):\n",
    "        r = random.randint(0, n-1)\n",
    "        a.append(x1[r])\n",
    "        b.append(y1[r])\n",
    "    return np.array(a), np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy is 0.03333333507180214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100, training accuracy is 0.8333333134651184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200, training accuracy is 0.9333333373069763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 300, training accuracy is 0.8999999761581421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 400, training accuracy is 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 500, training accuracy is 0.8999999761581421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 600, training accuracy is 0.8999999761581421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 700, training accuracy is 0.9666666388511658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 800, training accuracy is 0.9333333373069763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 900, training accuracy is 0.9666666388511658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000, training accuracy is 0.8999999761581421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1100, training accuracy is 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1200, training accuracy is 0.9666666388511658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1300, training accuracy is 0.8999999761581421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1400, training accuracy is 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1500, training accuracy is 0.9666666388511658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1600, training accuracy is 0.9666666388511658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700, training accuracy is 0.9666666388511658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1800, training accuracy is 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1900, training accuracy is 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9676983952522278\n"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "for i in range(2000):\n",
    "    batch_x, batch_y = get_random_cached(x1, y1,30)\n",
    "    if not i%100:\n",
    "        print(\"step {0}, training accuracy is {1}\".format(i, accuracy.eval(feed_dict={x:batch_x, y_:batch_y,keep_prob:1.0})))\n",
    "    train_step.run(feed_dict={x:batch_x,y_:batch_y,keep_prob:0.5})\n",
    "print(\"accuracy is {0}\".format(accuracy.eval(feed_dict={x:x2,y_:y2,keep_prob:1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\n   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n1     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n2     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n3     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n4     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n\n   pixel779  pixel780  pixel781  pixel782  pixel783  \n0       0.0       0.0       0.0       0.0       0.0  \n1       0.0       0.0       0.0       0.0       0.0  \n2       0.0       0.0       0.0       0.0       0.0  \n3       0.0       0.0       0.0       0.0       0.0  \n4       0.0       0.0       0.0       0.0       0.0  \n\n[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./digitRecognizer/test.csv').astype('float')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(test/255)\n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sess.run(y_conv,feed_dict={x:test,keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3210\n7    2906\n8    2862\n9    2838\n0    2832\n2    2777\n3    2759\n6    2724\n4    2686\n5    2406\ndtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.argmax(a,1).eval()\n",
    "c = pd.Series(b)\n",
    "c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n1    0\n2    9\n3    9\n4    3\ndtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.Series(b)\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3210\n7    2906\n8    2862\n9    2838\n0    2832\n2    2777\n3    2759\n6    2724\n4    2686\n5    2406\ndtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.41830851e-05,   8.40834957e-09,   9.99972582e-01,\n          3.64916195e-06,   2.72501353e-07,   3.94751360e-08,\n          7.09431561e-07,   2.26383875e-07,   6.81722668e-06,\n          1.54249187e-06],\n       [  9.99926805e-01,   2.40710456e-08,   1.19821907e-05,\n          1.22606491e-06,   2.78070256e-09,   4.26471815e-05,\n          7.34062132e-06,   5.87978229e-06,   4.33176581e-07,\n          3.67899293e-06],\n       [  4.92655672e-05,   2.66096613e-04,   2.99787673e-04,\n          9.87147796e-04,   4.70193988e-03,   1.10536488e-03,\n          1.13341121e-04,   2.23202654e-03,   3.01240496e-02,\n          9.60121036e-01],\n       [  7.65735954e-02,   5.94443176e-04,   1.59320652e-01,\n          1.38945458e-03,   3.11199240e-02,   7.61954929e-04,\n          9.13971569e-03,   8.98802802e-02,   1.08414795e-02,\n          6.20378494e-01],\n       [  7.54559660e-05,   3.33647593e-04,   4.70439792e-02,\n          9.48975980e-01,   4.70304713e-07,   3.55923665e-04,\n          5.52651836e-05,   1.37151455e-05,   3.06177652e-03,\n          8.37177577e-05],\n       [  5.17237231e-06,   4.35943235e-07,   6.91970563e-05,\n          3.74033843e-05,   1.44122469e-05,   1.62718345e-06,\n          7.01672036e-07,   9.87931311e-01,   6.81566889e-05,\n          1.18714506e-02],\n       [  9.99998331e-01,   6.79181023e-09,   4.55032307e-07,\n          3.51865737e-08,   2.53009413e-09,   6.18052365e-09,\n          7.52007963e-07,   1.99829445e-10,   4.37659963e-07,\n          3.84812360e-08],\n       [  4.23202721e-07,   7.39756842e-08,   9.23284460e-06,\n          9.99936581e-01,   8.06958127e-08,   3.62542255e-06,\n          2.84037061e-09,   1.16447360e-07,   6.60024762e-06,\n          4.32495217e-05],\n       [  9.99992847e-01,   4.47953408e-09,   1.52059545e-06,\n          4.65001193e-07,   3.92624155e-10,   3.04908554e-06,\n          7.68710947e-07,   2.09978580e-07,   7.10181425e-08,\n          1.09858502e-06],\n       [  1.06640186e-07,   1.34751258e-06,   9.60170564e-06,\n          9.99775827e-01,   1.94821240e-07,   1.74110246e-04,\n          8.13460517e-08,   2.42632893e-07,   3.74056290e-05,\n          1.14372381e-06],\n       [  1.91620893e-06,   9.68093872e-08,   5.61511477e-08,\n          2.06415352e-04,   4.90622199e-07,   9.99346316e-01,\n          1.53774795e-06,   3.92994423e-07,   3.59905156e-04,\n          8.27722615e-05],\n       [  1.87719212e-04,   4.81583993e-05,   2.83677559e-02,\n          8.69289273e-04,   7.41692247e-06,   9.77888794e-06,\n          1.99668875e-06,   9.59759474e-01,   4.08500928e-04,\n          1.03399437e-02],\n       [  3.60532977e-05,   7.78036410e-05,   8.12024300e-05,\n          8.86297692e-03,   7.73626745e-01,   4.73789929e-04,\n          9.87025560e-05,   1.03600763e-01,   2.52093244e-02,\n          8.79326314e-02],\n       [  9.99999881e-01,   1.08019468e-10,   1.91883416e-08,\n          1.07346265e-09,   1.73456475e-11,   1.37707368e-09,\n          1.29043002e-07,   2.29613972e-09,   1.63283840e-08,\n          2.50392063e-08],\n       [  1.43811640e-05,   5.94837638e-06,   1.84500786e-05,\n          1.04512410e-05,   9.70278502e-01,   8.89562216e-06,\n          1.32277753e-04,   2.73492537e-03,   1.34941447e-03,\n          2.54467651e-02],\n       [  8.41975212e-02,   1.06829408e-04,   6.11429568e-03,\n          8.47037256e-01,   9.50864251e-06,   1.58064310e-02,\n          3.93576920e-05,   1.10633460e-04,   3.97234522e-02,\n          6.85482100e-03],\n       [  1.38083543e-03,   9.74072667e-04,   2.37547583e-03,\n          9.89183426e-01,   2.65167660e-06,   4.35023243e-03,\n          2.74949038e-04,   1.79363255e-04,   1.22259022e-03,\n          5.63922331e-05],\n       [  3.65495653e-05,   9.97697055e-01,   8.67615527e-05,\n          1.05711973e-04,   7.66739249e-04,   2.35681146e-04,\n          3.71279690e-04,   1.19326382e-04,   5.16301778e-04,\n          6.46127883e-05],\n       [  1.48868622e-07,   4.13747057e-06,   1.25606107e-07,\n          1.65446745e-05,   7.91071652e-05,   1.03191087e-05,\n          4.98828641e-08,   2.81252083e-04,   8.14044150e-04,\n          9.98794198e-01],\n       [  9.99994755e-01,   2.73139866e-09,   5.74519731e-07,\n          3.81809606e-09,   7.58220597e-09,   1.89786604e-08,\n          3.81909967e-06,   1.04574891e-08,   3.66107173e-07,\n          4.77824074e-07],\n       [  4.08817186e-06,   2.24132350e-06,   2.62706862e-06,\n          1.43000188e-05,   5.49511497e-05,   1.75857917e-06,\n          6.20821794e-08,   8.79857969e-03,   1.21568002e-04,\n          9.90999758e-01],\n       [  3.45460580e-06,   9.99843240e-01,   2.17877277e-05,\n          9.50854087e-07,   3.85099411e-05,   1.39665781e-06,\n          2.16218650e-05,   1.04730861e-05,   5.73876387e-05,\n          1.15381681e-06],\n       [  2.11577553e-05,   9.92200911e-01,   1.18041469e-03,\n          1.94044449e-04,   6.81629230e-04,   1.99228884e-06,\n          3.12199554e-04,   1.82693300e-03,   3.55254207e-03,\n          2.82093315e-05],\n       [  8.83208850e-05,   6.81645542e-06,   1.15146884e-06,\n          7.35390995e-06,   1.43112652e-06,   9.99662161e-01,\n          9.36170181e-06,   1.08814102e-05,   1.93928019e-04,\n          1.86997695e-05],\n       [  5.76686894e-08,   1.74145107e-08,   7.65220193e-07,\n          2.54041879e-06,   2.35567288e-10,   7.02612439e-08,\n          4.92298494e-11,   9.99913216e-01,   1.88758094e-07,\n          8.31048383e-05],\n       [  8.57269697e-06,   7.49441970e-05,   1.55781322e-06,\n          1.37869310e-05,   9.68217134e-01,   2.37102122e-05,\n          5.63979338e-05,   2.82312860e-04,   1.15018644e-04,\n          3.12066283e-02],\n       [  2.77914811e-08,   2.16073590e-06,   9.99060452e-01,\n          6.75482850e-04,   8.82433596e-06,   5.93893560e-07,\n          3.90847345e-06,   2.98427594e-08,   2.48183613e-04,\n          3.75832457e-07],\n       [  1.18620601e-05,   6.03918124e-08,   4.64993413e-08,\n          2.05925767e-06,   6.81338975e-07,   4.66679552e-07,\n          2.16988472e-09,   9.99233007e-01,   8.22343281e-07,\n          7.51018350e-04],\n       [  6.65050247e-05,   2.12563928e-02,   1.40713426e-04,\n          3.01633525e-04,   4.34996694e-01,   5.40556503e-04,\n          1.67648817e-04,   4.99787480e-01,   1.99686978e-02,\n          2.27735993e-02],\n       [  9.54992902e-06,   1.50847552e-06,   1.63881341e-05,\n          9.40121663e-06,   4.22257820e-08,   8.84793820e-08,\n          1.87611811e-08,   9.99650359e-01,   2.09933205e-06,\n          3.10550997e-04],\n       [  4.84399461e-05,   5.62768309e-06,   1.48879774e-02,\n          9.34491516e-04,   2.30000097e-07,   8.82242784e-06,\n          4.17881608e-07,   9.82802927e-01,   1.36355127e-04,\n          1.17480522e-03],\n       [  1.13732298e-04,   1.81857158e-05,   5.83240253e-05,\n          9.50202812e-05,   3.48005528e-06,   9.98887718e-01,\n          1.15181632e-04,   2.02925494e-05,   6.59695710e-04,\n          2.84191410e-05],\n       [  2.20613661e-08,   1.73636508e-07,   1.07541140e-07,\n          8.87873384e-08,   9.99964356e-01,   7.98195288e-08,\n          2.96300504e-06,   1.75307050e-05,   2.01363875e-07,\n          1.44328997e-05],\n       [  1.74394190e-05,   6.57554483e-05,   9.96850312e-01,\n          1.04750786e-03,   6.06753847e-09,   3.63819993e-07,\n          2.09722839e-06,   1.19607250e-07,   2.01638229e-03,\n          2.25613199e-08],\n       [  7.09558080e-05,   1.11280450e-07,   2.01662442e-05,\n          9.15666689e-08,   3.39428479e-05,   1.37881525e-05,\n          9.99859929e-01,   1.00101598e-08,   8.42187148e-07,\n          2.14521592e-07],\n       [  1.58029593e-06,   9.61145997e-05,   9.98555481e-01,\n          4.82039555e-04,   4.82339786e-08,   2.34480424e-07,\n          2.21908158e-06,   1.70054002e-04,   6.86065760e-04,\n          6.13190923e-06],\n       [  2.61893054e-03,   2.37458051e-04,   6.63104001e-04,\n          7.27865481e-05,   2.37567801e-05,   9.65756118e-01,\n          3.49357113e-04,   1.35487190e-03,   1.99378491e-03,\n          2.69297045e-02],\n       [  2.07918376e-04,   1.24004218e-05,   3.04462969e-06,\n          1.40426100e-05,   1.39456661e-05,   9.99296427e-01,\n          5.23342460e-05,   4.07003699e-06,   3.87035863e-04,\n          8.76990089e-06],\n       [  1.03081793e-05,   9.85669494e-01,   1.12715759e-04,\n          2.66581750e-03,   3.28726205e-03,   3.85937194e-04,\n          1.09163811e-04,   4.88536782e-04,   6.02392899e-03,\n          1.24681473e-03],\n       [  7.91488513e-02,   5.77014271e-06,   2.78488478e-05,\n          1.16635318e-04,   7.19149693e-06,   2.81607895e-03,\n          9.14613783e-01,   4.80714607e-06,   3.19740828e-03,\n          6.16883990e-05],\n       [  3.41224440e-05,   9.31219438e-06,   3.97268741e-04,\n          6.36417244e-05,   1.19557751e-06,   2.79058258e-06,\n          4.57471771e-07,   9.98251259e-01,   1.56951191e-05,\n          1.22423237e-03],\n       [  3.88048704e-08,   1.13728609e-08,   1.02454339e-06,\n          1.02745389e-05,   7.62551758e-11,   3.77235310e-09,\n          9.39420902e-11,   9.99982953e-01,   1.00993081e-08,\n          5.65857135e-06],\n       [  3.97846556e-08,   2.79402485e-07,   7.29882174e-07,\n          1.16415029e-08,   9.99987483e-01,   2.35127597e-08,\n          8.00203452e-07,   1.33426079e-06,   2.66305307e-07,\n          9.01423118e-06],\n       [  2.20281936e-06,   3.78098861e-07,   2.65151562e-06,\n          7.64079346e-07,   2.20105983e-04,   2.69924016e-07,\n          4.65805243e-08,   1.17632642e-03,   4.32947963e-05,\n          9.98553932e-01],\n       [  5.94167323e-05,   1.53794768e-04,   2.71359721e-04,\n          1.03200357e-04,   6.36079712e-05,   1.12593751e-02,\n          4.96530160e-03,   2.53588278e-05,   9.82021332e-01,\n          1.07724057e-03],\n       [  8.76121504e-08,   1.61041868e-07,   3.45382489e-07,\n          1.80713541e-05,   1.68061465e-09,   4.86506337e-08,\n          1.36666889e-09,   9.99972463e-01,   3.57690162e-08,\n          8.69265477e-06],\n       [  9.63726143e-06,   3.39813450e-05,   5.76166494e-05,\n          3.51499359e-04,   1.40919019e-06,   1.75387358e-05,\n          1.33079193e-05,   1.42053177e-05,   9.99230385e-01,\n          2.70368619e-04],\n       [  6.78343931e-05,   1.05547369e-05,   2.30167836e-01,\n          1.26031805e-02,   1.82466469e-08,   7.35859749e-06,\n          2.01803709e-06,   6.55982831e-07,   7.57133663e-01,\n          6.87489364e-06],\n       [  2.58284458e-03,   7.25472867e-02,   4.11596295e-04,\n          3.54053773e-04,   2.50144559e-03,   1.24093995e-03,\n          8.90044868e-01,   3.50673727e-05,   2.95191314e-02,\n          7.62781478e-04],\n       [  3.72013397e-04,   3.10594328e-02,   4.22808677e-02,\n          1.39769642e-02,   1.80686242e-03,   2.38169194e-03,\n          1.68202590e-04,   8.13041210e-01,   3.69429402e-02,\n          5.79698011e-02],\n       [  1.05920459e-04,   1.05473148e-07,   7.18248202e-07,\n          5.35815410e-08,   1.58448995e-04,   1.45026627e-06,\n          9.99727666e-01,   1.72354664e-08,   2.08851884e-06,\n          3.47054129e-06],\n       [  1.17448644e-06,   1.14107399e-08,   2.38539287e-05,\n          5.01865543e-05,   2.36750793e-06,   2.76037772e-05,\n          5.20261949e-07,   1.34934425e-07,   9.99871016e-01,\n          2.31094182e-05],\n       [  4.50950320e-05,   1.40651048e-03,   1.26041326e-04,\n          1.21635139e-05,   9.45858210e-06,   8.97844075e-06,\n          9.93405774e-06,   2.20746933e-05,   9.98334587e-01,\n          2.51716774e-05],\n       [  7.47588217e-07,   3.68014028e-08,   2.46725904e-06,\n          9.99631286e-01,   8.15641688e-09,   1.41543587e-05,\n          2.81838419e-09,   5.34047651e-08,   3.31729680e-04,\n          1.95350458e-05],\n       [  1.42764179e-06,   2.50039966e-06,   8.06148819e-06,\n          9.97926691e-06,   1.50910284e-06,   8.87490969e-05,\n          1.41148166e-06,   7.45437865e-06,   9.99563634e-01,\n          3.15291400e-04],\n       [  3.53572176e-08,   3.83939351e-07,   9.99997258e-01,\n          5.77755713e-07,   1.97517465e-07,   1.59598024e-08,\n          9.97599614e-07,   1.42796948e-08,   6.20789137e-07,\n          2.89144508e-09],\n       [  1.31877614e-05,   9.98905778e-01,   1.10561290e-04,\n          2.37470049e-05,   4.93565341e-04,   3.76919388e-06,\n          3.16835474e-04,   4.33709356e-05,   7.67950769e-05,\n          1.22851961e-05],\n       [  1.13716191e-02,   1.19266533e-05,   9.50194657e-01,\n          9.94589936e-05,   4.02906735e-05,   8.94950881e-06,\n          3.08731396e-05,   1.59798679e-03,   3.60965803e-02,\n          5.47628442e-04],\n       [  4.33905807e-04,   1.76976679e-03,   9.53629315e-01,\n          6.18396560e-03,   1.87741704e-02,   4.07603430e-03,\n          2.17908924e-03,   6.81058038e-03,   1.06329843e-03,\n          5.07987803e-03],\n       [  7.89792836e-01,   5.59965702e-05,   4.25503909e-04,\n          1.50488550e-02,   1.90245119e-05,   1.64593339e-01,\n          7.44375074e-03,   1.66087854e-03,   3.91669339e-03,\n          1.70430429e-02],\n       [  3.56168712e-05,   2.15448381e-04,   2.16213666e-04,\n          4.67669801e-04,   9.49576795e-01,   2.73219630e-04,\n          4.44167847e-04,   2.09203959e-02,   1.46112323e-03,\n          2.63893157e-02],\n       [  2.72891430e-06,   9.99343812e-01,   2.09425372e-04,\n          1.24937560e-05,   2.30347490e-04,   4.76720800e-07,\n          3.12412849e-05,   1.29388340e-04,   3.82569306e-05,\n          1.72546481e-06],\n       [  3.91148342e-06,   4.60177853e-06,   6.04147208e-05,\n          4.89920285e-06,   6.33813841e-07,   9.85083716e-07,\n          2.42928362e-08,   9.99733508e-01,   5.48787784e-06,\n          1.85543395e-04],\n       [  9.99731958e-01,   2.55568267e-07,   2.41383605e-05,\n          5.90957768e-07,   1.72346199e-06,   2.55149030e-06,\n          1.75468769e-04,   1.26013879e-06,   7.06011133e-06,\n          5.49860124e-05],\n       [  9.99526978e-01,   6.37344783e-07,   1.42049612e-04,\n          1.16801596e-06,   1.81510347e-06,   1.31142906e-05,\n          2.08578320e-04,   1.81399173e-05,   2.67591986e-05,\n          6.07868169e-05],\n       [  9.99940515e-01,   1.70041723e-08,   5.22758364e-06,\n          1.33368037e-08,   1.98099812e-08,   4.77600395e-07,\n          5.19274545e-05,   2.30448416e-09,   1.79582389e-06,\n          1.02318715e-07],\n       [  1.14504197e-04,   9.84468877e-01,   2.01047762e-04,\n          2.22651899e-04,   8.39876535e-04,   4.04178536e-05,\n          4.04153470e-05,   1.22335814e-02,   1.09115057e-03,\n          7.47458776e-04],\n       [  2.87742514e-05,   5.67660609e-05,   7.93743384e-05,\n          2.52765778e-04,   1.57080013e-02,   1.74490968e-04,\n          7.87773097e-05,   4.59416769e-03,   1.05473213e-02,\n          9.68479574e-01],\n       [  9.99852896e-01,   9.25227628e-09,   9.31540035e-06,\n          4.09032381e-08,   5.17100922e-08,   1.75450157e-06,\n          1.32289671e-04,   3.89076540e-08,   3.18441766e-06,\n          4.85450187e-07],\n       [  3.72064346e-06,   9.99400020e-01,   7.74281507e-05,\n          1.17604040e-05,   5.80933520e-05,   1.65310064e-06,\n          1.75143883e-04,   2.22211202e-05,   2.42658440e-04,\n          7.32924354e-06],\n       [  7.05690545e-05,   1.96498672e-06,   1.47649616e-05,\n          1.00194632e-06,   9.88944066e-06,   1.91935644e-04,\n          9.99461472e-01,   7.84184309e-08,   2.44559400e-04,\n          3.68008045e-06],\n       [  2.62584181e-05,   2.28495719e-05,   1.14995550e-04,\n          1.38532836e-03,   5.68665826e-07,   9.90861535e-01,\n          1.10952742e-05,   1.04502078e-05,   5.57525456e-03,\n          1.99158257e-03],\n       [  5.20677361e-07,   9.19247789e-09,   4.66720849e-06,\n          1.22539088e-04,   6.24788981e-07,   8.84467590e-06,\n          2.01416199e-08,   4.14638066e-08,   9.99832749e-01,\n          2.99341955e-05],\n       [  3.60974286e-06,   2.63432469e-07,   3.21544503e-05,\n          1.31698471e-05,   6.35697745e-07,   1.79070537e-06,\n          2.62759431e-06,   8.57952998e-08,   9.99940515e-01,\n          5.13161422e-06],\n       [  5.74560408e-06,   7.38581593e-06,   9.99109924e-01,\n          5.57572566e-05,   1.09436705e-07,   5.24595293e-07,\n          3.33517482e-06,   7.41652984e-05,   7.35517300e-04,\n          7.51976768e-06],\n       [  3.07804730e-04,   1.23356102e-07,   7.62369791e-06,\n          7.11851753e-05,   6.41076667e-06,   5.75416425e-06,\n          6.77291473e-06,   2.54040373e-07,   9.99450147e-01,\n          1.43933969e-04],\n       [  2.45664472e-04,   2.62169215e-06,   8.25076771e-04,\n          6.29080757e-02,   9.17540892e-05,   4.43984382e-03,\n          9.27385770e-07,   6.25033397e-04,   6.70056105e-01,\n          2.60804921e-01],\n       [  3.42399971e-07,   1.13259766e-07,   1.16768796e-07,\n          1.30678864e-05,   1.85028213e-04,   9.88112788e-07,\n          4.40847074e-08,   4.01766971e-04,   6.01128486e-05,\n          9.99338329e-01],\n       [  2.15185958e-09,   5.80760116e-07,   9.99916673e-01,\n          8.17644395e-05,   3.24579688e-08,   2.73772738e-08,\n          1.86832949e-07,   2.05512535e-07,   4.34814098e-07,\n          2.70020561e-09],\n       [  1.02795536e-06,   5.23836889e-07,   2.23719049e-03,\n          9.96955037e-01,   4.48971216e-09,   4.61732998e-06,\n          8.70537747e-07,   1.21119047e-06,   7.99534842e-04,\n          4.55329854e-08],\n       [  3.26185618e-05,   6.26324709e-06,   1.60528216e-05,\n          1.40838034e-03,   1.74776073e-06,   9.97065365e-01,\n          2.62314552e-05,   6.16154193e-06,   1.32624561e-03,\n          1.10859270e-04],\n       [  2.73139263e-03,   9.35129542e-03,   8.72805249e-03,\n          9.37256729e-04,   7.16769993e-02,   1.26022962e-03,\n          7.46030780e-03,   1.40027210e-01,   1.90461166e-02,\n          7.38781154e-01],\n       [  8.66738628e-06,   9.99408484e-01,   2.16726694e-05,\n          7.01126919e-06,   3.25313827e-04,   6.22557673e-06,\n          4.55445770e-05,   8.63968598e-05,   7.12440815e-05,\n          1.95649918e-05],\n       [  9.98825490e-01,   3.39375561e-07,   2.91474225e-05,\n          4.81167808e-05,   1.44557885e-06,   4.19881189e-06,\n          3.85657586e-06,   3.91035792e-06,   1.01531867e-03,\n          6.81839083e-05],\n       [  6.55585927e-06,   2.24652649e-05,   9.23953558e-05,\n          2.67770611e-05,   4.56087384e-03,   1.30326616e-05,\n          2.84981229e-06,   2.56040395e-04,   9.21294675e-04,\n          9.94097710e-01],\n       [  2.61763557e-06,   6.37752819e-05,   9.99656677e-01,\n          5.32909180e-05,   3.24081317e-09,   3.11747570e-08,\n          1.86484122e-05,   1.49688219e-07,   2.04836673e-04,\n          8.48921822e-09],\n       [  1.06976955e-07,   1.36923774e-07,   1.09339408e-06,\n          4.41820475e-07,   9.99305129e-01,   2.75232168e-07,\n          4.86986346e-06,   9.16115141e-07,   8.45280647e-06,\n          6.78517797e-04],\n       [  5.00739225e-05,   1.30080889e-05,   3.21894372e-03,\n          9.92577374e-01,   7.07180163e-08,   7.80923176e-04,\n          1.81681685e-07,   5.44486102e-04,   2.72403797e-03,\n          9.07725262e-05],\n       [  1.78405389e-05,   3.63585116e-07,   1.19176830e-05,\n          9.39303035e-08,   7.68241589e-04,   2.10307953e-05,\n          9.99179184e-01,   1.89211733e-07,   3.93307744e-07,\n          7.35030369e-07],\n       [  7.65252335e-05,   5.92052949e-08,   9.27647932e-07,\n          6.85740133e-07,   6.41571603e-07,   4.01955549e-06,\n          1.26728432e-08,   9.99510884e-01,   1.23766688e-06,\n          4.04938357e-04],\n       [  6.36249206e-06,   2.88038922e-04,   9.83056605e-01,\n          5.38956979e-03,   8.94382026e-08,   4.77653793e-06,\n          1.70655619e-06,   1.64299081e-06,   1.12510119e-02,\n          1.45771580e-07],\n       [  9.99554336e-01,   1.50647665e-07,   6.19883067e-05,\n          8.98216399e-07,   1.65085453e-07,   5.79860207e-05,\n          1.21659768e-05,   1.39237997e-07,   2.96058424e-04,\n          1.60765740e-05],\n       [  2.56572348e-05,   1.25029476e-06,   7.60819148e-06,\n          1.78997755e-06,   1.20082623e-05,   7.79953771e-05,\n          9.99835372e-01,   1.24183011e-08,   3.78770783e-05,\n          3.52882523e-07],\n       [  1.66678055e-05,   3.33898441e-07,   3.29972067e-06,\n          7.95123754e-08,   1.98648672e-06,   4.98752852e-05,\n          9.99914050e-01,   3.55496077e-09,   1.36599247e-05,\n          6.17954541e-08],\n       [  3.26519250e-04,   9.33364511e-01,   2.43015680e-03,\n          3.33256292e-04,   1.30485324e-03,   1.93525455e-04,\n          1.14833436e-03,   6.68193772e-03,   5.35847619e-02,\n          6.32164476e-04],\n       [  4.18066520e-06,   1.06616877e-03,   9.52139089e-06,\n          1.16934029e-06,   9.85116422e-01,   4.44844090e-06,\n          5.88519797e-05,   5.39083085e-05,   4.82213567e-04,\n          1.32031115e-02],\n       [  3.31148478e-08,   6.63365540e-08,   1.95296110e-07,\n          9.99704063e-01,   6.45478551e-08,   1.59232877e-05,\n          3.12324033e-09,   2.66442697e-07,   5.41873414e-05,\n          2.25300508e-04],\n       [  6.71253511e-05,   2.86961422e-05,   8.62877059e-05,\n          6.31182687e-04,   3.29445611e-04,   9.85662118e-05,\n          6.13839666e-06,   4.47287783e-03,   1.63765214e-02,\n          9.77903187e-01],\n       [  4.64076891e-07,   1.72479517e-07,   5.61081265e-07,\n          2.16300123e-06,   4.60701024e-08,   3.89457369e-07,\n          1.03930500e-08,   9.99983907e-01,   2.61556607e-07,\n          1.20337781e-05],\n       [  3.77330070e-05,   3.06428759e-04,   5.39827597e-05,\n          5.38361310e-05,   9.74346519e-01,   2.26026357e-04,\n          5.27921598e-04,   1.84443202e-02,   8.28669639e-04,\n          5.17460378e-03]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'imageId': [_+1 for _ in range(len(c))],'label':c.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tensorflow.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}